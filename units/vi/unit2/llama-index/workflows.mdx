# T·∫°o c√°c workflow t√°c nh√¢n trong LlamaIndex

M·ªôt workflow trong LlamaIndex cung c·∫•p c√°ch c√≥ c·∫•u tr√∫c ƒë·ªÉ t·ªï ch·ª©c m√£ ngu·ªìn c·ªßa b·∫°n th√†nh c√°c b∆∞·ªõc tu·∫ßn t·ª± v√† qu·∫£n l√Ω ƒë∆∞·ª£c.

Workflow ƒë∆∞·ª£c t·∫°o b·∫±ng c√°ch ƒë·ªãnh nghƒ©a c√°c `Steps` (b∆∞·ªõc) ƒë∆∞·ª£c k√≠ch ho·∫°t b·ªüi `Events` (s·ª± ki·ªán), v√† ch√≠nh ch√∫ng ph√°t ra `Events` ƒë·ªÉ k√≠ch ho·∫°t c√°c b∆∞·ªõc ti·∫øp theo. H√£y xem Alfred minh h·ªça m·ªôt workflow LlamaIndex cho t√°c v·ª• RAG (T√¨m ki·∫øm v√† t·∫°o ra c√¢u tr·∫£ l·ªùi).

![S∆° ƒë·ªì workflow](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit2/llama-index/workflows.png)

**Workflow mang l·∫°i nh·ªØng l·ª£i √≠ch ch√≠nh:**

- T·ªï ch·ª©c m√£ ngu·ªìn r√µ r√†ng th√†nh c√°c b∆∞·ªõc ri√™ng bi·ªát
- Ki·∫øn tr√∫c h∆∞·ªõng s·ª± ki·ªán ƒë·ªÉ ki·ªÉm so√°t lu·ªìng linh ho·∫°t
- Giao ti·∫øp an to√†n ki·ªÉu d·ªØ li·ªáu gi·ªØa c√°c b∆∞·ªõc
- Qu·∫£n l√Ω tr·∫°ng th√°i t√≠ch h·ª£p s·∫µn
- H·ªó tr·ª£ c·∫£ t∆∞∆°ng t√°c t√°c nh√¢n ƒë∆°n gi·∫£n v√† ph·ª©c t·∫°p

Nh∆∞ b·∫°n c√≥ th·ªÉ ƒëo√°n, **workflow t·∫°o ra s·ª± c√¢n b·∫±ng tuy·ªát v·ªùi gi·ªØa t√≠nh t·ª± ch·ªß c·ªßa c√°c Agent (t√°c nh√¢n) trong khi v·∫´n duy tr√¨ ki·ªÉm so√°t to√†n b·ªô quy tr√¨nh.**

V·∫≠y h√£y c√πng h·ªçc c√°ch t·∫°o workflow n√†o!

## T·∫°o Workflow

<Tip>
B·∫°n c√≥ th·ªÉ theo d√µi m√£ ngu·ªìn trong <a href="https://huggingface.co/agents-course/notebooks/blob/main/unit2/llama-index/workflows.ipynb" target="_blank">notebook n√†y</a> v√† ch·∫°y b·∫±ng Google Colab.
</Tip>

### T·∫°o Workflow c∆° b·∫£n

<details>
<summary>C√†i ƒë·∫∑t g√≥i Workflow</summary>
Nh∆∞ ƒë√£ gi·ªõi thi·ªáu trong [ph·∫ßn v·ªÅ LlamaHub](llama-hub), ta c√≥ th·ªÉ c√†i ƒë·∫∑t g√≥i Workflow b·∫±ng l·ªánh:

```python
pip install llama-index-utils-workflow
```
</details>

Ta c√≥ th·ªÉ t·∫°o workflow m·ªôt b∆∞·ªõc b·∫±ng c√°ch ƒë·ªãnh nghƒ©a l·ªõp k·∫ø th·ª´a t·ª´ `Workflow` v√† trang tr√≠ h√†m b·∫±ng `@step`. Ch√∫ng m√¨nh c≈©ng c·∫ßn th√™m `StartEvent` v√† `StopEvent` - c√°c s·ª± ki·ªán ƒë·∫∑c bi·ªát ƒë·ªÉ ch·ªâ ƒë·ªãnh ƒëi·ªÉm b·∫Øt ƒë·∫ßu v√† k·∫øt th√∫c workflow.

```python
from llama_index.core.workflow import StartEvent, StopEvent, Workflow, step

class MyWorkflow(Workflow):
    @step
    async def my_step(self, ev: StartEvent) -> StopEvent:
        # th·ª±c hi·ªán m·ªôt s·ªë thao t√°c ·ªü ƒë√¢y
        return StopEvent(result="Xin ch√†o th·∫ø gi·ªõi!")


w = MyWorkflow(timeout=10, verbose=False)
result = await w.run()
```

Nh∆∞ b·∫°n th·∫•y, gi·ªù ta c√≥ th·ªÉ ch·∫°y workflow b·∫±ng c√°ch g·ªçi `w.run()`.

### K·∫øt n·ªëi nhi·ªÅu b∆∞·ªõc

ƒê·ªÉ k·∫øt n·ªëi nhi·ªÅu b∆∞·ªõc, ta **t·∫°o c√°c s·ª± ki·ªán t√πy ch·ªânh mang d·ªØ li·ªáu gi·ªØa c√°c b∆∞·ªõc.** C·∫ßn th√™m `Event` truy·ªÅn gi·ªØa c√°c b∆∞·ªõc v√† chuy·ªÉn k·∫øt qu·∫£ t·ª´ b∆∞·ªõc ƒë·∫ßu sang b∆∞·ªõc sau.

```python
from llama_index.core.workflow import Event

class ProcessingEvent(Event):
    intermediate_result: str

class MultiStepWorkflow(Workflow):
    @step
    async def step_one(self, ev: StartEvent) -> ProcessingEvent:
        # X·ª≠ l√Ω d·ªØ li·ªáu ban ƒë·∫ßu
        return ProcessingEvent(intermediate_result="B∆∞·ªõc 1 ho√†n th√†nh")

    @step
    async def step_two(self, ev: ProcessingEvent) -> StopEvent:
        # S·ª≠ d·ª•ng k·∫øt qu·∫£ trung gian
        final_result = f"X·ª≠ l√Ω xong: {ev.intermediate_result}"
        return StopEvent(result=final_result)

w = MultiStepWorkflow(timeout=10, verbose=False)
result = await w.run()
result
```

Vi·ªác g·ª£i √Ω ki·ªÉu d·ªØ li·ªáu ·ªü ƒë√¢y r·∫•t quan tr·ªçng ƒë·ªÉ ƒë·∫£m b·∫£o workflow ch·∫°y ƒë√∫ng. H√£y th·ª≠ l√†m ph·ª©c t·∫°p h∆°n m·ªôt ch√∫t!

### V√≤ng l·∫∑p v√† nh√°nh

G·ª£i √Ω ki·ªÉu d·ªØ li·ªáu l√† ph·∫ßn m·∫°nh m·∫Ω nh·∫•t c·ªßa workflow v√¨ cho ph√©p t·∫°o nh√°nh, v√≤ng l·∫∑p v√† ƒëi·ªÉm giao ƒë·ªÉ x√¢y d·ª±ng workflow ph·ª©c t·∫°p.

H√£y xem v√≠ d·ª• **t·∫°o v√≤ng l·∫∑p** b·∫±ng to√°n t·ª≠ union `|`. Trong v√≠ d·ª• d∆∞·ªõi, `LoopEvent` ƒë∆∞·ª£c d√πng l√†m ƒë·∫ßu v√†o cho b∆∞·ªõc v√† c≈©ng c√≥ th·ªÉ tr·∫£ v·ªÅ l√†m ƒë·∫ßu ra.

```python
from llama_index.core.workflow import Event
import random


class ProcessingEvent(Event):
    intermediate_result: str


class LoopEvent(Event):
    loop_output: str


class MultiStepWorkflow(Workflow):
    @step
    async def step_one(self, ev: StartEvent | LoopEvent) -> ProcessingEvent | LoopEvent:
        if random.randint(0, 1) == 0:
            print("ƒêi·ªÅu x·∫•u x·∫£y ra")
            return LoopEvent(loop_output="Quay l·∫°i b∆∞·ªõc m·ªôt.")
        else:
            print("ƒêi·ªÅu t·ªët x·∫£y ra")
            return ProcessingEvent(intermediate_result="B∆∞·ªõc ƒë·∫ßu ho√†n th√†nh.")

    @step
    async def step_two(self, ev: ProcessingEvent) -> StopEvent:
        # S·ª≠ d·ª•ng k·∫øt qu·∫£ trung gian
        final_result = f"X·ª≠ l√Ω xong: {ev.intermediate_result}"
        return StopEvent(result=final_result)


w = MultiStepWorkflow(verbose=False)
result = await w.run()
result
```

### V·∫Ω workflow

Ta c≈©ng c√≥ th·ªÉ v·∫Ω workflow. H√£y d√πng h√†m `draw_all_possible_flows` ƒë·ªÉ v·∫Ω workflow v√† l∆∞u v√†o file HTML.

```python
from llama_index.utils.workflow import draw_all_possible_flows

w = ... # nh∆∞ ƒë·ªãnh nghƒ©a ·ªü ph·∫ßn tr∆∞·ªõc
draw_all_possible_flows(w, "flow.html")
```

![V·∫Ω workflow](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit2/llama-index/workflow-draw.png)

C√≤n m·ªôt m·∫πo th√∫ v·ªã cu·ªëi c√πng m√† ch√∫ng ta s·∫Ω h·ªçc trong kh√≥a h·ªçc n√†y - kh·∫£ nƒÉng th√™m tr·∫°ng th√°i v√†o workflow.

### Qu·∫£n l√Ω tr·∫°ng th√°i

Qu·∫£n l√Ω tr·∫°ng th√°i h·ªØu √≠ch khi b·∫°n mu·ªën theo d√µi tr·∫°ng th√°i workflow ƒë·ªÉ m·ªçi b∆∞·ªõc ƒë·ªÅu truy c·∫≠p ƒë∆∞·ª£c c√πng tr·∫°ng th√°i. Ta c√≥ th·ªÉ l√†m ƒëi·ªÅu n√†y b·∫±ng c√°ch d√πng g·ª£i √Ω ki·ªÉu `Context` cho tham s·ªë trong h√†m b∆∞·ªõc.

```python
from llama_index.core.workflow import Context, StartEvent, StopEvent


@step
async def query(self, ctx: Context, ev: StartEvent) -> StopEvent:
    # l∆∞u truy v·∫•n v√†o context
    await ctx.set("query", "Th·ªß ƒë√¥ c·ªßa Ph√°p l√† g√¨?")

    # th·ª±c hi·ªán g√¨ ƒë√≥ v·ªõi context v√† s·ª± ki·ªán
    val = ...

    # l·∫•y truy v·∫•n t·ª´ context
    query = await ctx.get("query")

    return StopEvent(result=val)
```

Tuy·ªát v·ªùi! Gi·ªù b·∫°n ƒë√£ bi·∫øt c√°ch t·∫°o workflow c∆° b·∫£n trong LlamaIndex!

<Tip>B·∫°n c√≥ th·ªÉ t√¨m hi·ªÉu th√™m v·ªÅ c√°c chi ti·∫øt ph·ª©c t·∫°p c·ªßa workflow trong <a href="https://docs.llamaindex.ai/en/stable/understanding/workflows/">t√†i li·ªáu LlamaIndex</a>.</Tip>

Tuy nhi√™n c√≥ m·ªôt c√°ch kh√°c ƒë·ªÉ t·∫°o workflow b·∫±ng l·ªõp `AgentWorkflow`. H√£y c√πng xem c√°ch d√πng l·ªõp n√†y ƒë·ªÉ t·∫°o workflow ƒëa t√°c nh√¢n.

## T·ª± ƒë·ªông h√≥a workflow v·ªõi Multi-Agent Workflow

Thay v√¨ t·∫°o workflow th·ªß c√¥ng, ta c√≥ th·ªÉ d√πng **l·ªõp `AgentWorkflow` ƒë·ªÉ t·∫°o workflow ƒëa t√°c nh√¢n**. `AgentWorkflow` s·ª≠ d·ª•ng Workflow Agents cho ph√©p t·∫°o h·ªá th·ªëng g·ªìm m·ªôt ho·∫∑c nhi·ªÅu Agent (t√°c nh√¢n) c√≥ th·ªÉ h·ª£p t√°c v√† chuy·ªÉn giao t√°c v·ª• d·ª±a tr√™n kh·∫£ nƒÉng chuy√™n bi·ªát. ƒêi·ªÅu n√†y gi√∫p x√¢y d·ª±ng h·ªá th·ªëng Agent ph·ª©c t·∫°p v·ªõi c√°c Agent x·ª≠ l√Ω c√°c kh√≠a c·∫°nh kh√°c nhau c·ªßa t√°c v·ª•. Thay v√¨ import c√°c l·ªõp t·ª´ `llama_index.core.agent`, ta s·∫Ω import c√°c l·ªõp Agent t·ª´ `llama_index.core.agent.workflow`. M·ªôt Agent ph·∫£i ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh l√† root agent trong h√†m kh·ªüi t·∫°o `AgentWorkflow`. Khi ng∆∞·ªùi d√πng g·ª≠i tin nh·∫Øn, n√≥ s·∫Ω ƒë∆∞·ª£c chuy·ªÉn ƒë·∫øn root agent ƒë·∫ßu ti√™n.

M·ªói Agent c√≥ th·ªÉ:

- X·ª≠ l√Ω tr·ª±c ti·∫øp y√™u c·∫ßu b·∫±ng Tools c·ªßa h·ªç
- Chuy·ªÉn giao cho Agent kh√°c ph√π h·ª£p h∆°n
- Tr·∫£ l·ªùi ng∆∞·ªùi d√πng

H√£y xem c√°ch t·∫°o workflow ƒëa t√°c nh√¢n.

```python
from llama_index.core.agent.workflow import AgentWorkflow, ReActAgent
from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI

# ƒê·ªãnh nghƒ©a m·ªôt s·ªë c√¥ng c·ª•
def add(a: int, b: int) -> int:
    """C·ªông hai s·ªë."""
    return a + b

def multiply(a: int, b: int) -> int:
    """Nh√¢n hai s·ªë."""
    return a * b

llm = HuggingFaceInferenceAPI(model_name="Qwen/Qwen2.5-Coder-32B-Instruct")

# c√≥ th·ªÉ truy·ªÅn h√†m tr·ª±c ti·∫øp m√† kh√¥ng c·∫ßn FunctionTool - t√™n/m√¥ t·∫£ s·∫Ω ƒë∆∞·ª£c ph√¢n t√≠ch t·ª´ h√†m/docstring
multiply_agent = ReActAgent(
    name="multiply_agent",
    description="C√≥ th·ªÉ nh√¢n hai s·ªë nguy√™n",
    system_prompt="Tr·ª£ l√Ω h·ªØu √≠ch c√≥ th·ªÉ d√πng c√¥ng c·ª• ƒë·ªÉ nh√¢n s·ªë.",
    tools=[multiply],
    llm=llm,
)

addition_agent = ReActAgent(
    name="add_agent",
    description="C√≥ th·ªÉ c·ªông hai s·ªë nguy√™n",
    system_prompt="Tr·ª£ l√Ω h·ªØu √≠ch c√≥ th·ªÉ d√πng c√¥ng c·ª• ƒë·ªÉ c·ªông s·ªë.",
    tools=[add],
    llm=llm,
)

# T·∫°o workflow
workflow = AgentWorkflow(
    agents=[multiply_agent, addition_agent],
    root_agent="multiply_agent",
)

# Ch·∫°y h·ªá th·ªëng
response = await workflow.run(user_msg="B·∫°n c√≥ th·ªÉ c·ªông 5 v√† 3 kh√¥ng?")
```

C√°c Tools c·ªßa Agent c≈©ng c√≥ th·ªÉ ch·ªânh s·ª≠a tr·∫°ng th√°i workflow ƒë√£ ƒë·ªÅ c·∫≠p. Tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu workflow, ta c√≥ th·ªÉ cung c·∫•p state dict ban ƒë·∫ßu ƒë·ªÉ t·∫•t c·∫£ Agent truy c·∫≠p. Tr·∫°ng th√°i ƒë∆∞·ª£c l∆∞u trong key state c·ªßa workflow context v√† s·∫Ω ƒë∆∞·ª£c ƒë∆∞a v√†o state_prompt ƒë·ªÉ b·ªï sung cho m·ªói tin nh·∫Øn ng∆∞·ªùi d√πng m·ªõi.

H√£y th√™m b·ªô ƒë·∫øm s·ªë l·∫ßn g·ªçi h√†m b·∫±ng c√°ch s·ª≠a v√≠ d·ª• tr∆∞·ªõc:

```python
from llama_index.core.workflow import Context

# ƒê·ªãnh nghƒ©a m·ªôt s·ªë c√¥ng c·ª•
async def add(ctx: Context, a: int, b: int) -> int:
    """C·ªông hai s·ªë."""
    # c·∫≠p nh·∫≠t b·ªô ƒë·∫øm
    cur_state = await ctx.get("state")
    cur_state["num_fn_calls"] += 1
    await ctx.set("state", cur_state)

    return a + b

async def multiply(ctx: Context, a: int, b: int) -> int:
    """Nh√¢n hai s·ªë."""
    # c·∫≠p nh·∫≠t b·ªô ƒë·∫øm
    cur_state = await ctx.get("state")
    cur_state["num_fn_calls"] += 1
    await ctx.set("state", cur_state)

    return a * b

...

workflow = AgentWorkflow(
    agents=[multiply_agent, addition_agent],
    root_agent="multiply_agent"
    initial_state={"num_fn_calls": 0},
    state_prompt="Tr·∫°ng th√°i hi·ªán t·∫°i: {state}. Tin nh·∫Øn ng∆∞·ªùi d√πng: {msg}",
)

# ch·∫°y workflow v·ªõi context
ctx = Context(workflow)
response = await workflow.run(user_msg="B·∫°n c√≥ th·ªÉ c·ªông 5 v√† 3 kh√¥ng?", ctx=ctx)

# l·∫•y v√† ki·ªÉm tra tr·∫°ng th√°i
state = await ctx.get("state")
print(state["num_fn_calls"])
```

Ch√∫c m·ª´ng b·∫°n ƒë√£ n·∫Øm v·ªØng ki·∫øn th·ª©c c∆° b·∫£n v·ªÅ Agent trong LlamaIndex! üéâ

H√£y c√πng l√†m b√†i Ki·ªÉm tra nhanh cu·ªëi c√πng ƒë·ªÉ c·ªßng c·ªë ki·∫øn th·ª©c! üöÄ