# မိတ်ဆက် (Introduction)

![Bonus Unit 1 Thumbnail](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit1/thumbnail.jpg)

ဒီပထမဆုံး **အပိုဆောင်း အခန်း (Bonus Unit)** ကို ကြိုဆိုပါတယ်။ ဒီအခန်းမှာ သင်ဟာ **Function Calling အတွက် Large Language Model (LLM) တစ်ခုကို Fine-tune လုပ်နည်း** ကို လေ့လာရမှာ ဖြစ်ပါတယ်။

LLM တွေရဲ့ နည်းပညာနယ်ပယ်မှာ Function Calling ဟာ လျင်မြန်စွာနဲ့ **မဖြစ်မနေ သိထားရမယ့် နည်းလမ်း** တစ်ခု ဖြစ်လာနေပါတယ်။

ဒီနည်းလမ်းရဲ့ အဓိက အယူအဆကတော့ အခန်း (၁) မှာ လုပ်ခဲ့သလို Prompt ကိုသာ အားကိုးတဲ့ နည်းလမ်းတွေအပြင်၊ သင့်ရဲ့ မော်ဒယ်ကို **လေ့ကျင့်ရေး အဆင့် (Training Phase) မှာတင် လုပ်ဆောင်ချက်များ (Actions) ကို ယူဖို့နဲ့ ပတ်ဝန်းကျင်ရဲ့ တုံ့ပြန်ချက်များ (Observations) ကို နားလည်အောင်** လေ့ကျင့်ပေးခြင်းပဲ ဖြစ်ပါတယ်။ ဒီလိုလုပ်ခြင်းအားဖြင့် သင့်ရဲ့ AI ဟာ ပိုမို ခိုင်မာပြီး စွမ်းဆောင်ရည် မြင့်မားလာပါမယ်။

> **ဒီ Bonus Unit ကို ဘယ်အချိန်မှာ လုပ်သင့်သလဲ?**
>
> ဒီအပိုင်းဟာ **မဖြစ်မနေ လုပ်ဆောင်ရန် မလိုအပ်တဲ့ (Optional)** အပိုင်းဖြစ်ပြီး၊ အခန်း (၁) ထက် ပိုမို အဆင့်မြင့်ပါတယ်။ ဒါကြောင့် ဒီအခန်းကို အခုပဲ လုပ်ဆောင်မလား၊ ဒါမှမဟုတ် ဒီ Course ကနေ အသိပညာတွေ တိုးတက်လာတဲ့အခါမှ ပြန်လာပြီး လေ့လာမလားဆိုတာကို သင်ကိုယ်တိုင် ဆုံးဖြတ်နိုင်ပါတယ်။
>
> ဒါပေမယ့် စိတ်မပူပါနဲ့၊ ဒီ Bonus Unit ကို သင်ဟာ Fine-tuning ရဲ့ အတွင်းပိုင်း လုပ်ဆောင်ပုံတွေကို မသိသေးရင်တောင် Function Calling အတွက် မော်ဒယ်တစ်ခုကို Fine-tuning လုပ်တဲ့ အခြေခံ သဘောတရားတွေ အားလုံးကို လိုက်နာနိုင်အောင် ရေးဆွဲထားပါတယ်။

ဒီ Bonus Unit ကို အကောင်းဆုံး လိုက်နာနိုင်ဖို့အတွက် သင်သိထားသင့်တဲ့ အချက်တွေကတော့-

1.  **Transformers Library** ကို အသုံးပြုပြီး LLM တစ်ခုကို Fine-Tune လုပ်နည်းကို သိထားဖို့ လိုပါတယ်။ မသိသေးဘူးဆိုရင် [ဒီနေရာမှာ စစ်ဆေးလေ့လာနိုင်ပါတယ်](https://huggingface.co/learn/nlp-course/chapter3/1?fw=pt)။
2.  ကျွန်တော်တို့ရဲ့ မော်ဒယ်ကို Fine-tune လုပ်ဖို့အတွက် **`SFTTrainer`** ကို ဘယ်လို အသုံးပြုရမယ်ဆိုတာကို သိထားဖို့ လိုပါတယ်။ ပိုမိုသိရှိလိုပါက [ဒီ Documentation ကို ကြည့်ရှုနိုင်ပါတယ်](https://huggingface.co/learn/nlp-course/en/chapter11/1)။

---

## သင်ယူရမည့် အကြောင်းအရာများ (What You’ll Learn)

ဒီအခန်းမှာ အောက်ပါ အဓိက အကြောင်းအရာများကို လေ့လာသွားပါမယ်။

### ၁။ Function Calling (Function ခေါ်ဆိုခြင်း)

ခေတ်မီ LLM များသည် ၎င်းတို့၏ စကားပြောဆိုမှုများကို စနစ်တကျ ဖွဲ့စည်းပုံချခြင်းဖြင့် **Tools များ** ကို ထိရောက်စွာ အစပျိုး (Trigger) စေနိုင်ပုံကို လေ့လာပါမယ်။ (Function Calling ဆိုတာ LLM က သူ့ရဲ့ စကားပြောဆိုမှုထဲမှာ "ငါ အခု ဒီ Tool ကို သုံးမယ်" လို့ ပြောပြီး၊ အဲဒီ Tool ကို ခေါ်သုံးလိုက်တာမျိုး ဖြစ်ပါတယ်။)

### ၂။ LoRA (Low-Rank Adaptation)

**ပေါ့ပါးပြီး ထိရောက်တဲ့** Fine-tuning နည်းလမ်းတစ်ခုဖြစ်တဲ့ LoRA ကို လေ့လာပါမယ်။ LoRA ဟာ တွက်ချက်မှုဆိုင်ရာ ကုန်ကျစရိတ်နဲ့ သိုလှောင်မှုဆိုင်ရာ ဝန်ပိမှုတွေကို လျှော့ချပေးပါတယ်။ LoRA ကြောင့် မော်ဒယ်ကြီးတွေကို လေ့ကျင့်ပေးတာဟာ **ပိုမိုမြန်ဆန်၊ စရိတ်သက်သာပြီး အသုံးချဖို့ ပိုမိုလွယ်ကူ** လာပါတယ်။ (LoRA ဟာ မော်ဒယ်တစ်ခုလုံးကို ပြန်လေ့ကျင့်စရာမလိုဘဲ အရေးကြီးတဲ့ အစိတ်အပိုင်းလေးတွေကိုပဲ ချိန်ညှိပေးတာကြောင့် အချိန်နဲ့ စွမ်းအင်ကို သက်သာစေပါတယ်။)

### ၃။ Function Calling မော်ဒယ်များတွင် **Thought → Act → Observe Cycle**

သင့်ရဲ့ မော်ဒယ်က Functions တွေကို ဘယ်အချိန်မှာ (ဘယ်လို) ခေါ်ဆိုရမယ်၊ ကြားခံအဆင့်တွေကို ဘယ်လို မှတ်တမ်းတင်ရမယ်၊ ပြင်ပ Tools သို့မဟုတ် API များမှ ရလဒ်တွေကို ဘယ်လို နားလည်ရမယ်ဆိုတာကို ပုံစံချပေးတဲ့ ရိုးရှင်းပြီး အစွမ်းထက်တဲ့ ချဉ်းကပ်မှုတစ်ခု ဖြစ်ပါတယ်။

*   **Thought (စဉ်းစားခြင်း):** မော်ဒယ်က နောက်လုပ်ရမယ့် အဆင့်ကို စဉ်းစားတယ်။
*   **Act (လုပ်ဆောင်ခြင်း):** စဉ်းစားပြီးတဲ့အတိုင်း Tool ကို ခေါ်ဆိုပြီး လုပ်ဆောင်ချက် ယူတယ်။
*   **Observe (လေ့လာခြင်း):** Tool ကနေ ပြန်လာတဲ့ ရလဒ် (Observation) ကို လက်ခံရယူပြီး နောက်ထပ် ဆုံးဖြတ်ချက်အတွက် အသုံးပြုတယ်။

### ၄။ အထူး Token အသစ်များ (New Special Tokens)

မော်ဒယ်ကို အောက်ပါ အချက်များအကြား ခွဲခြားသိမြင်နိုင်စေရန် ကူညီပေးမည့် **အထူး သင်္ကေတများ (Special Markers)** ကို မိတ်ဆက်ပေးပါမယ်။

*   အတွင်းပိုင်း **"အတွေးဆက်တိုက် ဆင်ခြင်သုံးသပ်မှု" (Internal “chain-of-thought” reasoning)**
*   ပြင်ပသို့ ထွက်သွားသော **Function ခေါ်ဆိုမှုများ (Outgoing function calls)**
*   ပြင်ပ Tools များမှ ပြန်လာသော **တုံ့ပြန်ချက်များ (Responses coming back from external tools)**

---

ဒီ Bonus Unit ရဲ့ အဆုံးမှာ သင်ဟာ အောက်ပါတို့ကို လုပ်ဆောင်နိုင်မှာ ဖြစ်ပါတယ်။

*   Tools များနှင့် ပတ်သက်၍ API များ၏ အတွင်းပိုင်း လုပ်ဆောင်ပုံကို **နားလည်ခြင်း**။
*   LoRA နည်းလမ်းကို အသုံးပြုပြီး မော်ဒယ်တစ်ခုကို **Fine-tune လုပ်ခြင်း**။
*   ခိုင်မာပြီး ထိန်းသိမ်းရလွယ်ကူသော Function-calling Workflow များကို ဖန်တီးရန် **Thought → Act → Observe Cycle** ကို **အကောင်အထည်ဖော်ခြင်းနှင့် ပြုပြင်မွမ်းမံခြင်း**။
*   မော်ဒယ်၏ အတွင်းပိုင်း ဆင်ခြင်သုံးသပ်မှုနှင့် ပြင်ပ လုပ်ဆောင်ချက်များကို ချောမွေ့စွာ ခွဲခြားနိုင်ရန် အထူး Token များကို **ဒီဇိုင်းဆွဲပြီး အသုံးပြုခြင်း**။

ပြီးတော့ သင်ဟာ **Function Calling လုပ်နိုင်တဲ့ ကိုယ်ပိုင် မော်ဒယ်ကို Fine-tune လုပ်ပြီးသား** ဖြစ်ပါလိမ့်မယ်။ 🔥

Function Calling ကို စတင်လေ့လာလိုက်ရအောင်!