# အတွေး (Thought): အတွင်းပိုင်း ဆင်ခြင်သုံးသပ်မှုနှင့် ReAct နည်းလမ်း

> [!TIP]
> ဒီအပိုင်းမှာတော့ AI Agent တစ်ခုရဲ့ အတွင်းပိုင်း လုပ်ဆောင်ပုံ—**ဆင်ခြင်သုံးသပ်နိုင်စွမ်းနဲ့ စီမံခန့်ခွဲနိုင်စွမ်း**—ကို နက်နက်နဲနဲ လေ့လာသွားပါမယ်။ Agent တစ်ခုက အချက်အလက်တွေကို ခွဲခြမ်းစိတ်ဖြာဖို့၊ ရှုပ်ထွေးတဲ့ ပြဿနာတွေကို စီမံခန့်ခွဲနိုင်တဲ့ အဆင့်ငယ်လေးတွေအဖြစ် ခွဲထုတ်ဖို့နဲ့ နောက်ထပ် ဘာလုပ်ဆောင်ရမယ်ဆိုတာကို ဆုံးဖြတ်ဖို့အတွက် သူ့ရဲ့ အတွင်းပိုင်း ဆွေးနွေးမှု (Internal Dialogue) ကို ဘယ်လို အသုံးချသလဲဆိုတာကို လေ့လာသွားပါမယ်။
>
> ဒါ့အပြင်၊ မော်ဒယ်ကို လုပ်ဆောင်ချက် မပြုလုပ်ခင် **"တစ်ဆင့်ချင်းစီ စဉ်းစားပါ"** လို့ အားပေးတဲ့ Prompting နည်းလမ်းတစ်ခုဖြစ်တဲ့ **ReAct နည်းလမ်း** ကိုလည်း မိတ်ဆက်ပေးသွားပါမယ်။

**အတွေးများ (Thoughts)** ဆိုတာဟာ Task တစ်ခုကို ဖြေရှင်းဖို့အတွက် **Agent ရဲ့ အတွင်းပိုင်း ဆင်ခြင်သုံးသပ်မှုနဲ့ စီမံခန့်ခွဲမှု လုပ်ငန်းစဉ်များ** ကို ကိုယ်စားပြုပါတယ်။

ဒီလုပ်ငန်းစဉ်ဟာ Agent ရဲ့ Large Language Model (LLM) စွမ်းရည်ကို အသုံးပြုပြီး **Prompt ထဲမှာ ပေးထားတဲ့ အချက်အလက်တွေကို ခွဲခြမ်းစိတ်ဖြာ** စေပါတယ်။ အနှစ်ချုပ်ပြောရရင်၊ ပြဿနာတစ်ခုကို ဖြေရှင်းနေစဉ်အတွင်း Agent ရဲ့ **အတွင်းစိတ်က ပြောနေတဲ့ စကားသံ (Inner Monologue)** လိုမျိုးပါပဲ။

Agent ရဲ့ အတွေးတွေက လက်ရှိ ရရှိထားတဲ့ **လေ့လာတွေ့ရှိချက်များ (Observations)** ကို အကဲဖြတ်ဖို့နဲ့ နောက်ထပ် ဘာလုပ်ဆောင်ချက် (Action) တွေ လုပ်သင့်တယ်ဆိုတာကို ဆုံးဖြတ်ဖို့ ကူညီပေးပါတယ်။ ဒီလုပ်ငန်းစဉ်ကတစ်ဆင့် Agent ဟာ **ရှုပ်ထွေးတဲ့ ပြဿနာတွေကို သေးငယ်ပြီး စီမံခန့်ခွဲနိုင်တဲ့ အဆင့်ငယ်လေးတွေအဖြစ် ခွဲထုတ်နိုင်** ပါတယ်။ ဒါ့အပြင်၊ အရင်က အတွေ့အကြုံတွေကို ပြန်လည်သုံးသပ်နိုင်ပြီး အချက်အလက်အသစ်တွေအပေါ် အခြေခံပြီး သူ့ရဲ့ စီမံကိန်းတွေကို အဆက်မပြတ် ချိန်ညှိနိုင်ပါတယ်။

> **(ထပ်ဆောင်းအချက်အလက်):** လူသားတွေလိုပဲ၊ AI Agent တွေဟာလည်း ရှုပ်ထွေးတဲ့ ပြဿနာတွေကို ချက်ချင်းဖြေရှင်းနိုင်ခြင်း မရှိပါဘူး။ အတွေး (Thought) အဆင့်ဟာ Agent ကို အမှားလုပ်မိနိုင်ခြေကို လျှော့ချဖို့နဲ့ ပိုမိုကောင်းမွန်တဲ့ ဆုံးဖြတ်ချက်တွေ ချနိုင်ဖို့အတွက် အချိန်ပေး စဉ်းစားစေတာ ဖြစ်ပါတယ်။

## 🧠 အသုံးများသော အတွေး အမျိုးအစားများ (Examples of Common Thought Types)

| အတွေး အမျိုးအစား | ဥပမာ |
| :--- | :--- |
| **စီမံကိန်းချခြင်း (Planning)** | "ဒီ Task ကို အဆင့်သုံးဆင့် ခွဲလုပ်ရမယ်- ၁) ဒေတာစုဆောင်းမယ်၊ ၂) ခေတ်ရေစီးကြောင်းတွေကို ခွဲခြမ်းစိတ်ဖြာမယ်၊ ၃) အစီရင်ခံစာ ထုတ်ပေးမယ်။" |
| **ခွဲခြမ်းစိတ်ဖြာခြင်း (Analysis)** | "Error Message ကို ကြည့်ရတာ၊ ပြဿနာက Database ချိတ်ဆက်မှု Parameter တွေနဲ့ ပတ်သက်နေပုံရတယ်။" |
| **ဆုံးဖြတ်ချက်ချခြင်း (Decision Making)** | "အသုံးပြုသူရဲ့ ဘတ်ဂျက် အကန့်အသတ်ကြောင့်၊ အလယ်အလတ်တန်းစား ရွေးချယ်မှုကို အကြံပြုသင့်တယ်။" |
| **ပြဿနာဖြေရှင်းခြင်း (Problem Solving)** | "ဒီ Code ကို ပိုမိုကောင်းမွန်အောင် လုပ်ဖို့အတွက်၊ အရင်ဆုံး ဘယ်နေရာမှာ အချိန်ကုန်ဆုံးလဲဆိုတာကို ရှာဖွေရမယ်။" |
| **မှတ်ဉာဏ် ပေါင်းစပ်ခြင်း (Memory Integration)** | "အသုံးပြုသူက Python ကို ပိုကြိုက်တယ်လို့ အရင်က ပြောဖူးတယ်၊ ဒါကြောင့် Python ဥပမာတွေနဲ့ ပေးမယ်။" |
| **ကိုယ်တိုင် ပြန်လည်သုံးသပ်ခြင်း (Self-Reflection)** | "ငါ့ရဲ့ အရင်နည်းလမ်းက အဆင်မပြေခဲ့ဘူး၊ နောက်ထပ် မတူတဲ့ နည်းဗျူဟာတစ်ခုကို စမ်းကြည့်သင့်တယ်။" |
| **ပန်းတိုင် သတ်မှတ်ခြင်း (Goal Setting)** | "ဒီ Task ကို ပြီးမြောက်ဖို့အတွက်၊ အရင်ဆုံး လက်ခံနိုင်တဲ့ စံနှုန်းတွေကို သတ်မှတ်ဖို့ လိုတယ်။" |
| **ဦးစားပေး သတ်မှတ်ခြင်း (Prioritization)** | "လုံခြုံရေးဆိုင်ရာ အားနည်းချက်ကို Feature အသစ်တွေ မထည့်ခင် ဖြေရှင်းသင့်တယ်။" |

> **မှတ်ချက်:** Function-calling အတွက် Fine-tuning လုပ်ထားတဲ့ LLM တွေမှာတော့ အတွေးလုပ်ငန်းစဉ် (Thought Process) ဟာ မဖြစ်မနေ လိုအပ်တာမျိုး မဟုတ်ပါဘူး။ ဒီအကြောင်းကို Actions အပိုင်းမှာ ပိုမိုအသေးစိတ် ဆွေးနွေးထားပါတယ်။

## 🔗 Chain-of-Thought (CoT) - အတွေးဆက်တိုက် စီးဆင်းခြင်း

**Chain-of-Thought (CoT)** ဆိုတာဟာ မော်ဒယ်တစ်ခုကို **နောက်ဆုံးအဖြေ မထုတ်ခင် ပြဿနာတစ်ခုကို တစ်ဆင့်ချင်းစီ စဉ်းစားစေဖို့** လမ်းညွှန်ပေးတဲ့ Prompting နည်းလမ်းတစ်ခု ဖြစ်ပါတယ်။

ဒီနည်းလမ်းက အများအားဖြင့် အောက်ပါ စာသားနဲ့ စတင်လေ့ရှိပါတယ်-
> *"Let's think step by step."* (တစ်ဆင့်ချင်းစီ စဉ်းစားကြည့်ရအောင်။)

ဒီနည်းလမ်းက မော်ဒယ်ကို **ပြင်ပ Tool တွေနဲ့ ထိတွေ့ဆက်ဆံခြင်းမရှိဘဲ**၊ အထူးသဖြင့် Logic သို့မဟုတ် သင်္ချာဆိုင်ရာ Tasks တွေအတွက် **အတွင်းပိုင်း ဆင်ခြင်သုံးသပ်မှု** ပြုလုပ်ဖို့ ကူညီပေးပါတယ်။

### ✅ ဥပမာ (CoT)
```
Question: 200 ရဲ့ ၁၅% က ဘယ်လောက်လဲ။
Thought: တစ်ဆင့်ချင်းစီ စဉ်းစားကြည့်ရအောင်။ ၂၀၀ ရဲ့ ၁၀% က ၂၀ ဖြစ်ပြီး၊ ၅% က ၁၀ ဖြစ်တယ်။ ဒါကြောင့် ၁၅% က ၃၀ ဖြစ်တယ်။
Answer: 30
```

## ⚙️ ReAct: ဆင်ခြင်သုံးသပ်ခြင်း (Reasoning) + လုပ်ဆောင်ခြင်း (Acting)

အဓိကကျတဲ့ နည်းလမ်းတစ်ခုကတော့ **ReAct နည်းလမ်း** ဖြစ်ပြီး၊ ၎င်းသည် **"ဆင်ခြင်သုံးသပ်ခြင်း" (Think)** ကို **"လုပ်ဆောင်ခြင်း" (Act)** နဲ့ ပေါင်းစပ်ထားပါတယ်။

ReAct ဟာ မော်ဒယ်ကို တစ်ဆင့်ချင်းစီ စဉ်းစားစေပြီး၊ ဆင်ခြင်သုံးသပ်မှု အဆင့်များကြားမှာ လုပ်ဆောင်ချက်များ (ဥပမာ- Tool များ အသုံးပြုခြင်း) ကို ထည့်သွင်းစေတဲ့ Prompting နည်းလမ်းတစ်ခု ဖြစ်ပါတယ်။

ဒီနည်းလမ်းက Agent ကို ရှုပ်ထွေးတဲ့ Multi-step Tasks တွေကို ဖြေရှင်းနိုင်ဖို့အတွက် အောက်ပါ အဆင့်တွေကို အလှည့်ကျ လုပ်ဆောင်စေပါတယ်။

*   **Thought (အတွေး):** အတွင်းပိုင်း ဆင်ခြင်သုံးသပ်မှု
*   **Action (လုပ်ဆောင်ချက်):** Tool အသုံးပြုမှု
*   **Observation (လေ့လာတွေ့ရှိချက်):** Tool မှ ထွက်လာသော ရလဒ်ကို လက်ခံရယူခြင်း

### 🔄 ဥပမာ (ReAct)
```
Thought: ပဲရစ်မြို့ရဲ့ နောက်ဆုံး ရာသီဥတုကို ရှာဖို့ လိုတယ်။
Action: Search["weather in Paris"]
Observation: ၁၈°C ရှိပြီး တိမ်ထူနေပါတယ်။
Thought: အခု ရာသီဥတုကို သိပြီဆိုတော့...
Action: Finish["ပဲရစ်မြို့မှာ ၁၈°C ရှိပြီး တိမ်ထူနေပါတယ်။"]
```

<figure>
  <img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/ReAct.png" alt="ReAct"/>
  <figcaption>
    (d) သည် ReAct နည်းလမ်း၏ ဥပမာဖြစ်ပြီး၊ "တစ်ဆင့်ချင်းစီ စဉ်းစားကြည့်ရအောင်" ဟု Prompt ပေးပြီးနောက် မော်ဒယ်သည် အတွေးများကြားတွင် လုပ်ဆောင်ချက်များကို ထည့်သွင်း လုပ်ဆောင်သည်။
  </figcaption>
</figure>

## 🔁 နှိုင်းယှဉ်ချက်: ReAct နှင့် CoT

| Feature | Chain-of-Thought (CoT) | ReAct |
| :--- | :--- | :--- |
| **တစ်ဆင့်ချင်းစီ Logic** | ✅ ဟုတ်ကဲ့ | ✅ ဟုတ်ကဲ့ |
| **ပြင်ပ Tool များ** | ❌ မရှိပါ | ✅ ရှိပါသည် (Actions + Observations) |
| **အသင့်တော်ဆုံး Task များ** | Logic၊ သင်္ချာ၊ အတွင်းပိုင်း Tasks များ | အချက်အလက် ရှာဖွေခြင်း၊ ပြောင်းလဲနေသော Multi-step Tasks များ |

> [!TIP]
> **Deepseek R1** သို့မဟုတ် **OpenAI ရဲ့ o1** ကဲ့သို့သော မကြာသေးမီက ထွက်ရှိထားသည့် မော်ဒယ်များသည် **အဖြေမပေးမီ စဉ်းစားရန်** Fine-tuning လုပ်ထားပါတယ်။ ၎င်းတို့သည် ဆင်ခြင်သုံးသပ်မှု အဆင့်ကို နောက်ဆုံးအဖြေမှ ရှင်းရှင်းလင်းလင်း ခွဲခြားရန် `<think>` နှင့် `</think>` ကဲ့သို့သော Structured Tokens များကို အသုံးပြုပါတယ်။
>
> ReAct သို့မဟုတ် CoT တို့လို Prompting နည်းဗျူဟာများ မဟုတ်ဘဲ၊ ၎င်းသည် မော်ဒယ်က ဥပမာများမှတစ်ဆင့် စဉ်းစားတတ်အောင် သင်ယူစေသည့် **Training-level နည်းလမ်း** ဖြစ်ပါတယ်။