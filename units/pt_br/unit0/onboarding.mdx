# IntegraÃ§Ã£o: Seus Primeiros Passos â›µ

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit0/time-to-onboard.jpg" alt="Time to Onboard" width="100%"/>

Agora que vocÃª tem todos os detalhes, vamos comeÃ§ar! Vamos fazer quatro coisas:

1. **Criar sua Conta do Hugging Face** se ainda nÃ£o foi feito
2. **Inscrever-se no Discord e se apresentar** (nÃ£o seja tÃ­mido ğŸ¤—)
3. **Seguir o Curso de Agentes do Hugging Face** no Hub
4. **Espalhar a palavra** sobre o curso

### Passo 1: Criar sua Conta do Hugging Face

(Se vocÃª ainda nÃ£o fez) crie uma conta do Hugging Face <a href='https://huggingface.co/join' target='_blank'>aqui</a>.

### Passo 2: Juntar-se Ã  Nossa Comunidade Discord

ğŸ‘‰ğŸ» Junte-se ao nosso servidor discord <a href="https://discord.gg/UrrTSsSyjb" target="_blank">aqui.</a>

Quando vocÃª se juntar, lembre-se de se apresentar em `#introduce-yourself`.

Temos mÃºltiplos canais relacionados a Agentes de IA:
- `agents-course-announcements`: para as **Ãºltimas informaÃ§Ãµes do curso**.
- `ğŸ“-agents-course-general`: para **discussÃµes gerais e conversas**.
- `agents-course-questions`: para **fazer perguntas e ajudar seus colegas de classe**.
- `agents-course-showcase`: para **mostrar seus melhores agentes**.

AlÃ©m disso, vocÃª pode verificar:

- `smolagents`: para **discussÃ£o e suporte com a biblioteca**.

Se esta Ã© sua primeira vez usando Discord, escrevemos um Discord 101 para obter as melhores prÃ¡ticas. Verifique [a prÃ³xima seÃ§Ã£o](discord101).

### Passo 3: Seguir a OrganizaÃ§Ã£o do Curso de Agentes do Hugging Face

Mantenha-se atualizado com os materiais mais recentes do curso, atualizaÃ§Ãµes e anÃºncios **seguindo a OrganizaÃ§Ã£o do Curso de Agentes do Hugging Face**.

ğŸ‘‰ VÃ¡ <a href="https://huggingface.co/agents-course" target="_blank">aqui</a> e clique em **seguir**.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/hf_course_follow.gif" alt="Follow" width="100%"/>

### Passo 4: Espalhar a palavra sobre o curso

Ajude-nos a tornar este curso mais visÃ­vel! HÃ¡ duas maneiras de vocÃª nos ajudar:

1. Mostre seu apoio dando â­ <a href="https://github.com/huggingface/agents-course" target="_blank">ao repositÃ³rio do curso</a>.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/please_star.gif" alt="Repo star"/>

2. Compartilhe sua Jornada de Aprendizado: Deixe outros **saberem que vocÃª estÃ¡ fazendo este curso**! Preparamos uma ilustraÃ§Ã£o que vocÃª pode usar em suas postagens de mÃ­dia social

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png">

VocÃª pode baixar a imagem clicando ğŸ‘‰ [aqui](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png?download=true)

### Passo 5: Executando Modelos Localmente com Ollama (Caso vocÃª encontre limites de crÃ©dito)

1. **Instalar Ollama**

    Siga as instruÃ§Ãµes oficiais <a href="https://ollama.com/download" target="_blank"> aqui.</a>

2. **Baixar um modelo localmente**

    ```bash
    ollama pull qwen2:7b
    ```

    Aqui, baixamos o <a href="https://ollama.com/library/qwen2:7b" target="_blank"> modelo qwen2:7b</a>. Confira <a href="https://ollama.com/search" target="_blank">o site do ollama</a> para mais modelos.

3. **Iniciar Ollama em segundo plano (Em um terminal)**
    ``` bash
    ollama serve
    ``` 

    Se vocÃª encontrar o erro "listen tcp 127.0.0.1:11434: bind: address already in use", pode usar o comando `sudo lsof -i :11434` para identificar o ID do processo 
    (PID) que estÃ¡ atualmente usando esta porta. Se o processo for `ollama`, Ã© provÃ¡vel que o script de instalaÃ§Ã£o acima tenha iniciado o serviÃ§o ollama,
    entÃ£o vocÃª pode pular este comando para iniciar o Ollama.

4. **Usar `LiteLLMModel` em vez de `InferenceClientModel`**

   Para usar o mÃ³dulo `LiteLLMModel` no `smolagents`, vocÃª pode executar o comando `pip` para instalar o mÃ³dulo.

``` bash
    pip install 'smolagents[litellm]'
```

``` python
    from smolagents import LiteLLMModel

    model = LiteLLMModel(
        model_id="ollama_chat/qwen2:7b",  # Ou tente outros modelos suportados pelo Ollama
        api_base="http://127.0.0.1:11434",  # Servidor local padrÃ£o do Ollama
        num_ctx=8192,
    )
```

5. **Por que isso funciona?**
- O Ollama serve modelos localmente usando uma API compatÃ­vel com OpenAI em `http://localhost:11434`.
- `LiteLLMModel` foi construÃ­do para se comunicar com qualquer modelo que suporte o formato de API chat/completion do OpenAI.
- Isso significa que vocÃª pode simplesmente trocar `InferenceClientModel` por `LiteLLMModel` sem outras mudanÃ§as de cÃ³digo necessÃ¡rias. Ã‰ uma soluÃ§Ã£o perfeita e plug-and-play.

ParabÃ©ns! ğŸ‰ **VocÃª completou o processo de integraÃ§Ã£o**! Agora vocÃª estÃ¡ pronto para comeÃ§ar a aprender sobre Agentes de IA. Divirta-se!

Continue Aprendendo, permaneÃ§a incrÃ­vel ğŸ¤—
