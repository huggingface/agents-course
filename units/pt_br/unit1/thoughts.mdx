# Pensamento: RaciocÃ­nio Interno e a Abordagem ReAct

> [!TIP]
> Nesta seÃ§Ã£o mergulhamos no funcionamento interno de um agente de IA â€” sua capacidade de raciocinar e planejar. Vamos ver como o agente usa seu diÃ¡logo interno para analisar informaÃ§Ãµes, dividir problemas complexos em etapas menores e decidir qual aÃ§Ã£o executar em seguida.
>
> TambÃ©m apresentamos a abordagem ReAct, uma tÃ©cnica de prompting que incentiva o modelo a â€œpensar passo a passoâ€ antes de agir.

Os pensamentos representam o **raciocÃ­nio e o planejamento internos do agente** para cumprir uma tarefa.

Eles aproveitam a capacidade do LLM de **analisar informaÃ§Ãµes presentes no prompt** â€” essencialmente, Ã© o monÃ³logo interno do agente enquanto resolve o problema.

Por meio dos pensamentos, o agente avalia as observaÃ§Ãµes atuais e decide qual(is) aÃ§Ã£o(Ãµes) executar. Esse processo permite **decompor problemas complexos em etapas menores**, refletir sobre experiÃªncias anteriores e ajustar planos conforme surgem novas informaÃ§Ãµes.

## ğŸ§  Exemplos comuns de pensamentos

| Tipo de pensamento   | Exemplo                                                                 |
|----------------------|-------------------------------------------------------------------------|
| Planejamento         | "Preciso dividir a tarefa em trÃªs etapas: 1) coletar dados, 2) analisar tendÃªncias, 3) gerar relatÃ³rio" |
| AnÃ¡lise              | "Com base na mensagem de erro, o problema parece estar nos parÃ¢metros de conexÃ£o com o banco" |
| Tomada de decisÃ£o    | "Dado o orÃ§amento do usuÃ¡rio, devo recomendar a opÃ§Ã£o intermediÃ¡ria"    |
| ResoluÃ§Ã£o de problemas | "Para otimizar este cÃ³digo, devo primeiro perfilÃ¡-lo e identificar gargalos" |
| IntegraÃ§Ã£o de memÃ³ria| "O usuÃ¡rio mencionou que prefere Python; vou dar exemplos em Python"    |
| AutoavaliaÃ§Ã£o        | "Minha abordagem anterior nÃ£o funcionou bem; vou tentar outra estratÃ©gia" |
| DefiniÃ§Ã£o de metas   | "Para concluir esta tarefa, preciso estabelecer os critÃ©rios de aceitaÃ§Ã£o" |
| PriorizaÃ§Ã£o          | "A vulnerabilidade de seguranÃ§a deve ser corrigida antes de adicionar novos recursos" |

> **ObservaÃ§Ã£o:** em LLMs ajustados para function calling, o raciocÃ­nio pode ser opcional. Veremos mais detalhes na seÃ§Ã£o de AÃ§Ãµes.

## ğŸ”— Chain-of-Thought (CoT)

**Chain-of-Thought (CoT)** Ã© uma tÃ©cnica de prompting que orienta o modelo a **pensar passo a passo antes de gerar a resposta final**.

Geralmente comeÃ§a com:
> *"Vamos pensar passo a passo."*

Essa abordagem ajuda o modelo a **raciocinar internamente**, especialmente em tarefas lÃ³gicas ou matemÃ¡ticas, **sem usar ferramentas externas**.

### âœ… Exemplo (CoT)
```
Pergunta: Quanto Ã© 15% de 200?
Pensamento: Vamos pensar passo a passo. 10% de 200 Ã© 20, e 5% de 200 Ã© 10, entÃ£o 15% Ã© 30.
Resposta: 30
```

## âš™ï¸ ReAct: Reasoning + Acting

Um mÃ©todo importante Ã© a abordagem **ReAct**, que combina â€œRaciocinarâ€ (Think) com â€œAgirâ€ (Act).

ReAct Ã© uma tÃ©cnica de prompting que incentiva o modelo a pensar passo a passo e a intercalar aÃ§Ãµes (como uso de ferramentas) entre as etapas de raciocÃ­nio.

Isso permite que o agente resolva tarefas complexas alternando entre:

- Pensamento: raciocÃ­nio interno  
- AÃ§Ã£o: uso de ferramenta  
- ObservaÃ§Ã£o: retorno da ferramenta

### ğŸ”„ Exemplo (ReAct)
```
Pensamento: Preciso descobrir a previsÃ£o do tempo mais recente em Paris.
AÃ§Ã£o: Search["weather in Paris"]
ObservaÃ§Ã£o: EstÃ¡ 18Â°C e nublado.
Pensamento: Agora que sei o clima...
AÃ§Ã£o: Finish["EstÃ¡ 18Â°C e nublado em Paris."]
```

<figure>
  <img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/ReAct.png" alt="ReAct"/>
  <figcaption>
    (d) Ã© um exemplo da abordagem ReAct, em que incentivamos â€œVamos pensar passo a passoâ€ e o modelo executa aÃ§Ãµes entre os pensamentos.
  </figcaption>
</figure>

## ğŸ” ComparaÃ§Ã£o: ReAct vs. CoT

| CaracterÃ­stica              | Chain-of-Thought (CoT)      | ReAct                                   |
|-----------------------------|-----------------------------|-----------------------------------------|
| LÃ³gica passo a passo        | âœ… Sim                      | âœ… Sim                                  |
| Uso de ferramentas externas | âŒ NÃ£o                      | âœ… Sim (AÃ§Ãµes + ObservaÃ§Ãµes)            |
| Melhor para                 | LÃ³gica, matemÃ¡tica, tarefas internas | Busca de informaÃ§Ã£o, tarefas dinÃ¢micas multi-etapas |

> [!TIP]
> Modelos recentes como **Deepseek R1** ou **OpenAI o1** foram ajustados para *pensar antes de responder*. Eles utilizam tokens estruturados como `<think>` e `</think>` para separar explicitamente a fase de raciocÃ­nio da resposta final.
>
> Diferentemente do ReAct ou do CoT â€” que sÃ£o estratÃ©gias de prompting â€” isso Ã© uma **tÃ©cnica de treinamento**, na qual o modelo aprende a pensar atravÃ©s de exemplos.
