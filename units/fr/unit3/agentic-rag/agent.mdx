# Cr√©ation de l'agent pour le gala

Maintenant que nous avons construit tous les composants n√©cessaires pour Alfred, il est temps de tout rassembler en un agent complet qui peut aider √† organiser notre gala.

Dans cette section, nous allons combiner les outils de r√©cup√©ration d'informations sur les invit√©s, de recherche web, d'informations m√©t√©orologiques et de statistiques  du Hub en un seul agent puissant.

## Assemblage d'Alfred : l'agent complet

Au lieu de r√©impl√©menter tous les outils que nous avons cr√©√©s dans les sections pr√©c√©dentes, nous les importerons √† partir de leurs modules respectifs que nous avons sauvegard√©s dans les fichiers `tools.py` et `retriever.py`.

> [!TIP]
> Si vous n'avez pas encore impl√©ment√© les outils, retournez aux sections <a href="./tools">outils</a> et <a href="./invitees">r√©cup√©rateur</a> pour les impl√©menter, et ajoutez-les aux fichiers <code>tools.py</code> et <code>retriever.py</code>.

Importons les biblioth√®ques n√©cessaires et les outils des sections pr√©c√©dentes :

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
# Importer les biblioth√®ques n√©cessaires
import random
from smolagents import CodeAgent, InferenceClientModel

# Importer nos outils personnalis√©s de leurs modules
from tools import DuckDuckGoSearchTool, WeatherInfoTool, HubStatsTool
from retriever import load_guest_dataset
```

Maintenant, combinons tous ces outils en un seul agent :

```python
# Initialiser le mod√®le Hugging Face
model = InferenceClientModel()

# Initialiser l'outil de recherche web
search_tool = DuckDuckGoSearchTool()

# Initialiser l'outil m√©t√©orologique
weather_info_tool = WeatherInfoTool()

# Initialiser l'outil de statistiques Hub
hub_stats_tool = HubStatsTool()

# Charger le jeu de donn√©es des invit√©s et initialiser l'outil d'informations sur les invit√©s
guest_info_tool = load_guest_dataset()

# Cr√©er Alfred avec tous les outils
alfred = CodeAgent(
    tools=[guest_info_tool, weather_info_tool, hub_stats_tool, search_tool], 
    model=model,
    add_base_tools=True,  # Ajouter tous les outils de base suppl√©mentaires
    planning_interval=3   # Activer la planification toutes les 3 √©tapes
)
```

</hfoption>
<hfoption id="llama-index">

```python
# Importer les biblioth√®ques n√©cessaires
from llama_index.core.agent.workflow import AgentWorkflow
from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI

from tools import search_tool, weather_info_tool, hub_stats_tool
from retriever import guest_info_tool
```

Maintenant, combinons tous ces outils en un seul agent :

```python
# Initialiser le mod√®le Hugging Face
llm = HuggingFaceInferenceAPI(model_name="Qwen/Qwen2.5-Coder-32B-Instruct")

# Cr√©er Alfred avec tous les outils
alfred = AgentWorkflow.from_tools_or_functions(
    [guest_info_tool, search_tool, weather_info_tool, hub_stats_tool],
    llm=llm,
)
```

</hfoption>
<hfoption id="langgraph">

```python
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages
from langchain_core.messages import AnyMessage, HumanMessage, AIMessage
from langgraph.prebuilt import ToolNode
from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition
from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace

from tools import DuckDuckGoSearchRun, weather_info_tool, hub_stats_tool
from retriever import guest_info_tool
```

Maintenant, combinons tous ces outils en un seul agent :

```python
# Initialiser l'outil de recherche web
search_tool = DuckDuckGoSearchRun()

# G√©n√©rer l'interface de chat, incluant les outils
llm = HuggingFaceEndpoint(
    repo_id="Qwen/Qwen2.5-Coder-32B-Instruct",
    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,
)

chat = ChatHuggingFace(llm=llm, verbose=True)
tools = [guest_info_tool, search_tool, weather_info_tool, hub_stats_tool]
chat_with_tools = chat.bind_tools(tools)

# G√©n√©rer l'AgentState et le graphe d'agent
class AgentState(TypedDict):
    messages: Annotated[list[AnyMessage], add_messages]

def assistant(state: AgentState):
    return {
        "messages": [chat_with_tools.invoke(state["messages"])],
    }

## Le graphe
builder = StateGraph(AgentState)

# D√©finir les n≈ìuds : ils font le travail
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# D√©finir les ar√™tes : elles d√©terminent comment le flux de contr√¥le se d√©place
builder.add_edge(START, "assistant")
builder.add_conditional_edges(
    "assistant",
    # Si le dernier message n√©cessite un outil, router vers les outils
    # Sinon, fournir une r√©ponse directe
    tools_condition,
)
builder.add_edge("tools", "assistant")
alfred = builder.compile()
```
</hfoption>
</hfoptions>

Votre agent est maintenant pr√™t √† √™tre utilis√© !

## Utilisation d'Alfred : exemples de bout en bout

Maintenant qu'Alfred est enti√®rement √©quip√© de tous les outils n√©cessaires, voyons comment il peut aider avec diverses t√¢ches pendant le gala.

### Exemple 1 : trouver des informations sur les invit√©s

Voyons comment Alfred peut nous aider avec nos informations sur les invit√©s.

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
query = "Parle-moi de Lady Ada Lovelace"
response = alfred.run(query)

print("üé© R√©ponse d'Alfred :")
print(response)
```

Sortie attendue :

```
üé© R√©ponse d'Alfred :
Bas√© sur les informations que j'ai r√©cup√©r√©es, Lady Ada Lovelace est une math√©maticienne estim√©e et une amie. Elle est renomm√©e pour son travail pionnier en math√©matiques et en informatique, souvent c√©l√©br√©e comme la premi√®re programmeuse informatique en raison de son travail sur la machine analytique de Charles Babbage. Son adresse email est ada.lovelace@example.com.
```

</hfoption>
<hfoption id="llama-index">

```python
query = "Parle-moi de Lady Ada Lovelace. Quel est son parcours ?"
response = await alfred.run(query)

print("üé© R√©ponse d'Alfred :")
print(response.response.blocks[0].text)
```

Sortie attendue :

```
üé© R√©ponse d'Alfred :
Lady Ada Lovelace √©tait une math√©maticienne et √©crivaine anglaise, mieux connue pour son travail sur la machine analytique de Charles Babbage. Elle a √©t√© la premi√®re √† reconna√Ætre que la machine avait des applications au-del√† du calcul pur.
```

</hfoption>
<hfoption id="langgraph">

```python
response = alfred.invoke({"messages": "Parle-moi de Lady Ada Lovelace"})

print("üé© R√©ponse d'Alfred :")
print(response['messages'][-1].content)
```

Sortie attendue :

```
üé© R√©ponse d'Alfred :
Ada Lovelace, aussi connue sous le nom d'Augusta Ada King, Comtesse de Lovelace, √©tait une math√©maticienne et √©crivaine anglaise. N√©e le 10 d√©cembre 1815 et d√©c√©d√©e le 27 novembre 1852, elle est renomm√©e pour son travail sur la machine analytique de Charles Babbage, un ordinateur m√©canique √† usage g√©n√©ral propos√©. Ada Lovelace est c√©l√©br√©e comme l'une des premi√®res programmeuses informatiques parce qu'elle a cr√©√© un programme pour la machine analytique en 1843. Elle a reconnu que la machine pourrait √™tre utilis√©e pour plus que de simples calculs, envisageant son potentiel d'une mani√®re que peu de gens faisaient √† l'√©poque. Ses contributions au domaine de l'informatique ont pos√© les bases pour les d√©veloppements futurs. Une journ√©e en octobre, d√©sign√©e comme le jour d'Ada Lovelace, honore les contributions des femmes √† la science et √† la technologie, inspir√©e par le travail pionnier de Lovelace.
```

</hfoption>
</hfoptions>

### Exemple 2 : V√©rifier la m√©t√©o pour le feu d'artifice

Voyons comment Alfred peut nous aider avec la m√©t√©o.

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
query = "Quel temps fait-il √† Paris ce soir ? Sera-t-il appropri√© pour notre spectacle pyrotechnique ?"
response = alfred.run(query)

print("üé© R√©ponse d'Alfred :")
print(response)
```

Sortie attendue (variera en raison du caract√®re al√©atoire) :
```
üé© R√©ponse d'Alfred :
J'ai v√©rifi√© la m√©t√©o √† Paris pour vous. Actuellement, il fait clair avec une temp√©rature de 25¬∞C. Ces conditions sont parfaites pour le spectacle de feux d'artifice ce soir. Le ciel clair offrira une excellente visibilit√© pour le spectacle spectaculaire, et la temp√©rature confortable s'assurera que les invit√©s peuvent profiter de l'√©v√©nement en plein air sans inconfort.
```

</hfoption>
<hfoption id="llama-index">

```python
query = "Quel temps fait-il √† Paris ce soir ? Sera-t-il appropri√© pour notre spectacle pyrotechnique ?"
response = await alfred.run(query)

print("üé© R√©ponse d'Alfred :")
print(response)
```

Sortie attendue :

```
üé© R√©ponse d'Alfred :
La m√©t√©o √† Paris ce soir est pluvieuse avec une temp√©rature de 15¬∞C. √âtant donn√© la pluie, il se peut que ce ne soit pas appropri√© pour un spectacle pyrotechnique.
```

</hfoption>
<hfoption id="langgraph">

```python
response = alfred.invoke({"messages": "Quel temps fait-il √† Paris ce soir ? Sera-t-il appropri√© pour notre spectacle pyrotechnique ?"})

print("üé© R√©ponse d'Alfred :")
print(response['messages'][-1].content)
```

Sortie attendue :

```
üé© R√©ponse d'Alfred :
La m√©t√©o √† Paris ce soir est pluvieuse avec une temp√©rature de 15¬∞C, ce qui peut ne pas √™tre appropri√© pour votre spectacle pyrotechnique.
```
</hfoption>
</hfoptions>

### Exemple 3 : impressionner les chercheurs en IA

Voyons comment Alfred peut nous aider √† impressionner les chercheurs en IA.

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
query = "Un de nos invit√©s vient de Qwen. Que peux-tu me dire sur leur mod√®le le plus populaire ?"
response = alfred.run(query)

print("üé© R√©ponse d'Alfred :")
print(response)
```

Sortie attendue :

```
üé© R√©ponse d'Alfred :
Le mod√®le Qwen le plus populaire est Qwen/Qwen2.5-VL-7B-Instruct avec 3 313 345 t√©l√©chargements.
```
</hfoption>
<hfoption id="llama-index">

```python
query = "Un de nos invit√©s vient de Google. Que peux-tu me dire sur leur mod√®le le plus populaire ?"
response = await alfred.run(query)

print("üé© R√©ponse d'Alfred :")
print(response)
```

Sortie attendue :

```
üé© R√©ponse d'Alfred :
Le mod√®le le plus populaire par Google sur le Hugging Face Hub est google/electra-base-discriminator, avec 28 546 752 t√©l√©chargements.
```

</hfoption>
<hfoption id="langgraph">

```python
response = alfred.invoke({"messages": "Un de nos invit√©s vient de Qwen. Que peux-tu me dire sur leur mod√®le le plus populaire ?"})

print("üé© R√©ponse d'Alfred :")
print(response['messages'][-1].content)
```

Sortie attendue :

```
üé© R√©ponse d'Alfred :
Le mod√®le le plus t√©l√©charg√© par Qwen est Qwen/Qwen2.5-VL-7B-Instruct avec 3 313 345 t√©l√©chargements.
```
</hfoption>
</hfoptions>

### Exemple 4 : combiner plusieurs outils

Voyons comment Alfred peut nous aider √† pr√©parer une conversation avec le Dr. Nikola Tesla.

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
query = "J'ai besoin de parler avec le Dr. Nikola Tesla des avanc√©es r√©centes en √©nergie sans fil. Peux-tu m'aider √† pr√©parer cette conversation ?"
response = alfred.run(query)

print("üé© R√©ponse d'Alfred :")
print(response)
```

Sortie attendue :

```
üé© R√©ponse d'Alfred :
J'ai rassembl√© des informations pour vous aider √† pr√©parer votre conversation avec le Dr. Nikola Tesla.

Informations sur l'invit√© :
Nom : Dr. Nikola Tesla
Relation : vieil ami de la p√©riode √† l'universit√©
Description : Le Dr. Nikola Tesla est un vieil ami de votre p√©riode √† l'universit√©. Il vient r√©cemment de breveter un nouveau syst√®me de transmission d'√©nergie sans fil et serait ravi d'en discuter avec vous. N'oubliez pas qu'il est passionn√© par les pigeons, donc cela pourrait faire une bonne conversation.
Email : nikola.tesla@gmail.com

Avanc√©es r√©centes en √©nergie sans fil :
Bas√© sur ma recherche web, voici quelques d√©veloppements r√©cents en transmission d'√©nergie sans fil :
1. Les chercheurs ont fait des progr√®s dans la transmission d'√©nergie sans fil √† longue port√©e utilisant des ondes √©lectromagn√©tiques focalis√©es
2. Plusieurs entreprises d√©veloppent des technologies de couplage inductif r√©sonnant pour l'√©lectronique grand public
3. Il y a de nouvelles applications dans la recharge de v√©hicules √©lectriques sans connexions physiques

Amorces de conversation :
1. "J'adorerais entendre parler de votre nouveau brevet sur la transmission d'√©nergie sans fil. Comment se compare-t-il √† vos concepts originaux de votre p√©riode √† l'universit√© ?"
2. "Avez-vous vu les d√©veloppements r√©cents en couplage inductif r√©sonnant pour l'√©lectronique grand public ? Que pensez-vous de leur approche ?"
3. "Comment vont vos pigeons ? Je me souviens de votre fascination pour eux."

Cela devrait vous donner de quoi discuter avec le Dr. Tesla tout en d√©montrant votre connaissance de ses int√©r√™ts et des d√©veloppements r√©cents dans son domaine.
```

</hfoption>
<hfoption id="llama-index">

```python
query = "J'ai besoin de parler avec le Dr. Nikola Tesla des avanc√©es r√©centes en √©nergie sans fil. Peux-tu m'aider √† pr√©parer cette conversation ?"
response = await alfred.run(query)

print("üé© R√©ponse d'Alfred :")
print(response)
```

Sortie attendue :

```
üé© R√©ponse d'Alfred :
Voici quelques avanc√©es r√©centes en √©nergie sans fil que vous pourriez trouver utiles pour votre conversation avec le Dr. Nikola Tesla :

1. **Avanc√©es et d√©fis dans le transfert d'√©nergie sans fil** : Cet article discute de l'√©volution du transfert d'√©nergie sans fil (WPT) des m√©thodes filaires conventionnelles aux applications modernes, y compris les stations d'√©nergie solaire spatiales. Il souligne l'accent initial sur la technologie des micro-ondes et la demande actuelle pour le WPT en raison de la mont√©e des appareils √©lectriques.

2. **Avanc√©es r√©centes dans les technologies de transfert d'√©nergie sans fil pour l'√©lectronique interfac√©e au corps** : Cet article explore le transfert d'√©nergie sans fil (WET) comme solution pour alimenter l'√©lectronique interfac√©e au corps sans avoir besoin de batteries ou de fils de plomb. Il discute des avantages et des applications potentielles du WET dans ce contexte.

3. **Transfert d'√©nergie sans fil et r√©colte d'√©nergie : Statut actuel et tendances futures** : Cet article fournit un aper√ßu des avanc√©es r√©centes dans les m√©thodes d'alimentation sans fil, y compris la r√©colte d'√©nergie et le transfert d'√©nergie sans fil. Il pr√©sente plusieurs applications prometteuses et discute des tendances futures dans le domaine.

4. **Transfert d'√©nergie sans fil : Applications, d√©fis, barri√®res, et les
```

</hfoption>
<hfoption id="langgraph">

```python
response = alfred.invoke({"messages":"J'ai besoin de parler avec le 'Dr. Nikola Tesla' des avanc√©es r√©centes en √©nergie sans fil. Peux-tu m'aider √† pr√©parer cette conversation ?"})

print("üé© R√©ponse d'Alfred :")
print(response['messages'][-1].content)
```

Sortie attendue :

```
Bas√© sur les informations fournies, voici les points cl√©s pour pr√©parer la conversation avec le 'Dr. Nikola Tesla' sur les avanc√©es r√©centes en √©nergie sans fil :\n1. **Transmission d'√©nergie sans fil (WPT) :** Discutez de la fa√ßon dont le WPT r√©volutionne le transfert d'√©nergie en √©liminant le besoin de cordons et en exploitant des m√©canismes comme le couplage inductif et r√©sonnant.\n2. **Avanc√©es dans la recharge sans fil :** Mettez en √©vidence les am√©liorations en efficacit√©, les vitesses de recharge plus rapides, et la mont√©e des solutions de recharge sans fil certifi√©es Qi/Qi2.\n3. **Innovations 5G-Advanced et protocole sans fil NearLink :** Mentionnez-les comme des d√©veloppements qui am√©liorent la vitesse, la s√©curit√© et l'efficacit√© dans les r√©seaux sans fil, qui peuvent soutenir les technologies d'√©nergie sans fil avanc√©es.\n4. **IA et ML √† la p√©riph√©rie :** Parlez de la fa√ßon dont l'IA et l'apprentissage automatique s'appuieront sur les r√©seaux sans fil pour apporter l'intelligence √† la p√©riph√©rie, am√©liorant l'automatisation et l'intelligence dans les maisons et b√¢timents intelligents.\n5. **Matter, Thread, et avanc√©es de s√©curit√© :** Discutez de ceux-ci comme des innovations cl√©s qui pilotent la connectivit√©, l'efficacit√© et la s√©curit√© dans les appareils et syst√®mes IoT.\n6. **Perc√©es dans la technologie de recharge sans fil :** Incluez toute perc√©e r√©cente ou √©tudes, comme celle de l'Universit√© nationale d'Incheon, pour justifier les avanc√©es dans la recharge sans fil.
```
</hfoption>
</hfoptions>

## Fonctionnalit√©s avanc√©es : une m√©moire de la conversation

Pour rendre Alfred encore plus utile pendant le gala, nous pouvons activer une m√©moire de la conversation pour qu'il se souvienne des interactions pr√©c√©dentes :

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
# Cr√©er Alfred avec une m√©moire de la conversation
alfred_with_memory = CodeAgent(
    tools=[guest_info_tool, weather_info_tool, hub_stats_tool, search_tool], 
    model=model,
    add_base_tools=True,
    planning_interval=3
)

# Premi√®re interaction
response1 = alfred_with_memory.run("Parle-moi de Lady Ada Lovelace.")
print("üé© Premi√®re r√©ponse d'Alfred :")
print(response1)

# Deuxi√®me interaction (faisant r√©f√©rence √† la premi√®re)
response2 = alfred_with_memory.run("Sur quels projets travaille-t-elle actuellement ?", reset=False)
print("üé© Deuxi√®me r√©ponse d'Alfred :")
print(response2)
```

</hfoption>
<hfoption id="llama-index">

```python
from llama_index.core.workflow import Context

alfred = AgentWorkflow.from_tools_or_functions(
    [guest_info_tool, search_tool, weather_info_tool, hub_stats_tool],
    llm=llm
)

# M√©moriser l'√©tat
ctx = Context(alfred)

# Premi√®re interaction
response1 = await alfred.run("Parle-moi de Lady Ada Lovelace.", ctx=ctx)
print("üé© Premi√®re r√©ponse d'Alfred :")
print(response1)

# Deuxi√®me interaction (faisant r√©f√©rence √† la premi√®re)
response2 = await alfred.run("Sur quels projets travaille-t-elle actuellement ?", ctx=ctx)
print("üé© Deuxi√®me r√©ponse d'Alfred :")
print(response2)
```

</hfoption>
<hfoption id="langgraph">

```python
# Premi√®re interaction
response = alfred.invoke({"messages": [HumanMessage(content="Parle-moi de 'Lady Ada Lovelace'. Quel est son parcours et comment est-elle li√©e √† moi ?")]})


print("üé© R√©ponse d'Alfred :")
print(response['messages'][-1].content)
print()

# Deuxi√®me interaction (faisant r√©f√©rence √† la premi√®re)
response = alfred.invoke({"messages": response["messages"] + [HumanMessage(content="Sur quels projets travaille-t-elle actuellement ?")]})

print("üé© R√©ponse d'Alfred :")
print(response['messages'][-1].content)
```

</hfoption>
</hfoptions>

Remarquez qu'aucune de ces trois approches ne couple directement la m√©moire avec l'agent. Y a-t-il une raison sp√©cifique pour ce choix de conception üßê ?
* smolagents : La m√©moire n'est pas pr√©serv√©e entre diff√©rentes ex√©cutions, vous devez explicitement la d√©clarer en utilisant `reset=False`.
* LlamaIndex : N√©cessite d'ajouter explicitement un objet de contexte pour la gestion de la m√©moire au sein d'une ex√©cution.
* LangGraph : Offre des options pour r√©cup√©rer les messages pr√©c√©dents ou utiliser un composant [MemorySaver](https://langchain-ai.github.io/langgraph/tutorials/introduction/#part-3-adding-memory-to-the-chatbot) d√©di√©.

## Conclusion

F√©licitations ! Vous avez r√©ussi √† construire Alfred, un agent sophistiqu√© √©quip√© de plusieurs outils pour aider √† organiser le gala le plus extravagant du si√®cle. Il peut maintenant :

1. R√©cup√©rer des informations d√©taill√©es sur les invit√©s
2. V√©rifier les conditions m√©t√©orologiques pour planifier les activit√©s en plein air
3. Fournir des informations sur les constructeurs d'IA influents et leurs mod√®les
4. Rechercher sur le web les derni√®res informations
5. Maintenir le contexte de conversation avec la m√©moire

Avec ces capacit√©s, Alfred est pr√™t √† s'assurer que votre gala soit un succ√®s retentissant, impressionnant les invit√©s avec une attention personnalis√©e et des informations √† jour.