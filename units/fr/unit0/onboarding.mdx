# Embarquement : vos premiers pas ‚õµ

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit0/time-to-onboard.jpg" alt="Il est temps de d√©marrer" width="100%"/>

Maintenant que vous avez tous les d√©tails, commen√ßons ! Nous allons r√©aliser quatre choses :

1. **Cr√©er votre compte Hugging Face** si ce n'est pas d√©j√† fait  
2. **Vous inscrire √† Discord et vous pr√©senter** (ne soyez pas timide ü§ó)  
3. **Suivre le cours sur les agents** sur le ü§ó Hub  
4. **Faire passer le mot** √† propos du cours

### √âtape 1 : Cr√©er votre compte Hugging Face

(Si ce n'est pas d√©j√† fait) cr√©ez un compte Hugging Face <a href='https://huggingface.co/join' target='_blank'>ici</a>.

### √âtape 2 : Rejoindre notre Discord

üëâüèª Rejoignez notre serveur Discord <a href="https://discord.gg/UrrTSsSyjb" target="_blank">ici.</a>

Lorsque vous rejoignez, n'oubliez pas de vous pr√©senter dans `#introduce-yourself`.

Consultez le canal `courses` sur le `Hugging Face Hub` pour toutes les questions et demandes li√©es aux cours.

Si c'est votre premi√®re utilisation de Discord, nous avons r√©dig√© un guide d'introduction pour vous donner les meilleures pratiques. Consultez [la section suivante](discord101).

### √âtape 3 : Suivre l'organisation *Hugging Face Agent Course* sur le ü§ó Hub

Restez √† jour avec les derniers mat√©riels de cours, mises √† jour, et annonces **en suivant l'organisation du cours sur le Hub**.

üëâ Rendez-vous <a href="https://huggingface.co/agents-course" target="_blank">ici</a> et cliquez sur **suivre**.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/hf_course_follow.gif" alt="Suivre" width="100%"/>

### √âtape 4 : Faites passer le mot √† propos du cours

Aidez-nous √† rendre ce cours plus visible ! Il y a deux fa√ßons de nous aider :

1. Montrez votre soutien en <a href="https://github.com/huggingface/agents-course" target="_blank">laissant une √©toile ‚≠ê sur le d√©p√¥t du cours</a>.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/please_star.gif" alt="Favoriser le d√©p√¥t"/>

2. Partagez votre parcours d'apprentissage : faites savoir aux autres **que vous suivez ce cours** ! Nous avons pr√©par√© une illustration que vous pouvez utiliser dans vos publications sur les r√©seaux sociaux.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png" alt="Partagez votre parcours d'apprentissage" width="100%"/>

Vous pouvez t√©l√©charger l'image en cliquant üëâ [ici](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png?download=true)

### √âtape 5 : Ex√©cuter des mod√®les localement avec Ollama (En cas de limites de cr√©dits)

1. **Installez Ollama**

    Suivez les instructions officielles <a href="https://ollama.com/download" target="_blank">ici.</a>

2. **T√©l√©chargez un mod√®le localement**
``` bash
    ollama pull qwen2:7b # Consultez le site web d'Ollama pour plus de mod√®les
```
3. **D√©marrez Ollama en arri√®re-plan (dans un terminal)**
``` bash
    ollama serve
``` 
    Si vous rencontrez l'erreur "*listen tcp 127.0.0.1:11434: bind: address already in use*", vous pouvez utiliser la commande `sudo lsof -i :11434` pour identifier l'ID du processus (PID) qui utilise actuellement ce port. Si le processus est `ollama`, il est probable que le script d'installation ci-dessus ait d√©marr√© le service ollama, vous pouvez donc ignorer cette commande pour d√©marrer Ollama.

4. **Utilisez `LiteLLMModel` au lieu de `InferenceClientModel`**

   Pour utiliser le module `LiteLLMModel` dans `smolagents`, vous pouvez ex√©cuter la commande `pip` pour installer le module.

``` bash
    pip install 'smolagents[litellm]'
```

``` python
    from smolagents import LiteLLMModel

    model = LiteLLMModel(
        model_id="ollama_chat/qwen2:7b",  # Ou essayez d'autres mod√®les support√©s par Ollama
        api_base="http://127.0.0.1:11434",  # Serveur local Ollama par d√©faut
        num_ctx=8192,
    )
```

5. **Pourquoi cela fonctionne-t-il ?**
- Ollama sert des mod√®les localement en utilisant une API compatible avec OpenAI √† `http://localhost:11434`.
- `LiteLLMModel` est con√ßu pour communiquer avec tout mod√®le qui supporte le format d'API OpenAI chat/completion.
- Cela signifie que vous pouvez simplement remplacer `InferenceClientModel` par `LiteLLMModel` sans autres changements de code n√©cessaires. C'est une solution transparente et pr√™te √† l'emploi.

F√©licitations ! üéâ  
**Vous avez termin√© le processus d'embarquement** ! Vous √™tes maintenant pr√™t √† commencer √† en apprendre plus  sur les agents IA. Amusez-vous bien !

Continuez √† apprendre, restez formidable ü§ó
